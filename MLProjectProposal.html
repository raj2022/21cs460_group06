<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_poqkuuranaj6-3>li:before{content:"\0025cf  "}.lst-kix_poqkuuranaj6-5>li:before{content:"\0025a0  "}.lst-kix_2ey7dxn5ubpm-7>li:before{content:"\0025cb  "}.lst-kix_2ey7dxn5ubpm-8>li:before{content:"\0025a0  "}.lst-kix_poqkuuranaj6-0>li:before{content:"\0025cf  "}.lst-kix_poqkuuranaj6-4>li:before{content:"\0025cb  "}.lst-kix_2ey7dxn5ubpm-5>li:before{content:"\0025a0  "}.lst-kix_2ey7dxn5ubpm-6>li:before{content:"\0025cf  "}.lst-kix_poqkuuranaj6-1>li:before{content:"\0025cb  "}.lst-kix_poqkuuranaj6-2>li:before{content:"\0025a0  "}ul.lst-kix_2ey7dxn5ubpm-8{list-style-type:none}ul.lst-kix_2ey7dxn5ubpm-7{list-style-type:none}ul.lst-kix_2ey7dxn5ubpm-4{list-style-type:none}ul.lst-kix_2ey7dxn5ubpm-3{list-style-type:none}ul.lst-kix_2ey7dxn5ubpm-6{list-style-type:none}ul.lst-kix_2ey7dxn5ubpm-5{list-style-type:none}ul.lst-kix_2ey7dxn5ubpm-0{list-style-type:none}ul.lst-kix_2ey7dxn5ubpm-2{list-style-type:none}ul.lst-kix_2ey7dxn5ubpm-1{list-style-type:none}ul.lst-kix_poqkuuranaj6-8{list-style-type:none}ul.lst-kix_poqkuuranaj6-7{list-style-type:none}ul.lst-kix_poqkuuranaj6-6{list-style-type:none}ul.lst-kix_poqkuuranaj6-5{list-style-type:none}ul.lst-kix_poqkuuranaj6-4{list-style-type:none}ul.lst-kix_poqkuuranaj6-3{list-style-type:none}ul.lst-kix_poqkuuranaj6-2{list-style-type:none}ul.lst-kix_poqkuuranaj6-1{list-style-type:none}ul.lst-kix_poqkuuranaj6-0{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_2ey7dxn5ubpm-1>li:before{content:"\0025cb  "}.lst-kix_2ey7dxn5ubpm-2>li:before{content:"\0025a0  "}.lst-kix_2ey7dxn5ubpm-0>li:before{content:"\0025cf  "}.lst-kix_2ey7dxn5ubpm-3>li:before{content:"\0025cf  "}.lst-kix_2ey7dxn5ubpm-4>li:before{content:"\0025cb  "}.lst-kix_poqkuuranaj6-8>li:before{content:"\0025a0  "}.lst-kix_poqkuuranaj6-7>li:before{content:"\0025cb  "}.lst-kix_poqkuuranaj6-6>li:before{content:"\0025cf  "}ol{margin:0;padding:0}table td,table th{padding:0}.c10{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c5{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c8{padding:0;margin:0}.c3{margin-left:36pt;padding-left:0pt}.c4{font-size:12pt}.c7{font-style:italic}.c6{font-size:15pt}.c2{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c5"><p class="c9"><span class="c6">To generate the next few frames in a video using Graph neural networks.</span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c10">Goal or motivation:</span></p><p class="c1 c2"><span class="c10"></span></p><ul class="c8 lst-kix_poqkuuranaj6-0 start"><li class="c1 c3 li-bullet-0"><span class="c0">To predict the next few frames of the video using a Graph Neural Network for Spatio-temporal graphs.</span></li><li class="c1 c3 li-bullet-0"><span class="c0">To know about the nodes a few frames later.</span></li></ul><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c4">A graph</span><span class="c4 c7">&nbsp;G</span><span class="c4">&nbsp;is an ordered pair of a set</span><span class="c4 c7">&nbsp;V</span><span class="c4">&nbsp;of vertices and a set </span><span class="c4 c7">E</span><span class="c4">&nbsp;of edges. A graph </span><span class="c4 c7">G</span><span class="c4">&nbsp;can be defined as </span><span class="c4 c7">G</span><span class="c4">&nbsp;= (</span><span class="c4 c7">V, E</span><span class="c4">), where </span><span class="c4 c7">V</span><span class="c4">&nbsp;is the set of nodes, and </span><span class="c4 c7">E</span><span class="c0">&nbsp;are the edges between them.</span></p><p class="c1"><span class="c0">Graph data exists in many fields. For example, in medicine and pharmacy in which atoms or molecules can be taken as nodes(vertices) and their bond distance as edges, or in social media networks, people can be taken as nodes and their age or gender as attributes. </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c10">What can we do with graph data in machine learning?</span></p><p class="c1 c2"><span class="c10"></span></p><p class="c1"><span class="c0">We can do multiple things. We can perform node-level prediction. Graph with unlabelled nodes and want to predict attributes about these notes or classify them. We can find information about the other nodes. We can also use link prediction or edge-level prediction to find connections between nodes.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c10">Problems with graph data?</span></p><p class="c1 c2"><span class="c10"></span></p><p class="c1"><span class="c0">The size and shape of the graph might change within a dataset. We need a method for arbitrary input shapes. 2 graphs that look different can be structurally identical. This issue can be solved with the help of permutation invariant.</span></p><p class="c1"><span class="c0">GNNs are neural networks that can be applied to graphs, making node-level, edge-level, and graph-level prediction tasks easy. Node classification (the objective here is to determine the labeling of samples by looking at the labels of their neighbors), Graph classification, Graph Visualization, Link Prediction, and Graph Clustering are just a few examples of GNN applications.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c10">How will we proceed?</span></p><p class="c1 c2"><span class="c10"></span></p><p class="c1"><span class="c0">&nbsp;Here we will use Graph Neural Network(GNN) to determine the next few video frames and further about a few frames. The multiple frames add the temporal aspect to the graph. Hence, the graph generated from the number of frames is a Spatio-temporal graph.</span></p><p class="c1"><span class="c0">From the above figure, we can observe that an image can be represented as graphs by dividing the image into regions and the neighboring regions, which are interconnected. The video consists of multiple frames. Using the above methods, the frame can be converted into a graph. &nbsp;</span></p><p class="c1"><span class="c0">Since a large amount of video data is captured, Video summarizing is used to condense the original video into a short summary while preserving the main content. Lots of videos summarizing approaches have been proposed but, a fully convolutional structure on time axis approach has gained significantly.</span></p><p class="c1"><span class="c0">Forecasting traffic speed, volume or the density of roads in traffic networks is fundamentally important in a smart transportation system. We can address the traffic prediction problem by using STGNNs or STCNs.Considering the traffic network as a spatial-temporal graph where the nodes are sensors installed on roads, the edges are measured by the distance between pairs of nodes, and each node has the average traffic speed within a window as dynamic input features.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c10">Midway through the Project:</span></p><p class="c1 c2"><span class="c10"></span></p><p class="c1"><span class="c0">We will try to understand how to implement Graph Neural Network on the extracted frame from the video and also we will try to train the model and predict the few frames of the video for the Spatio-temporal graph.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c10">Relevant Papers:</span></p><ul class="c8 lst-kix_2ey7dxn5ubpm-0 start"><li class="c1 c3 li-bullet-0"><span class="c0">Bing Yu, Haoteng Yin, Zhanxing Zhu. &nbsp;Spatio -Temporal Graph Convolutional Networks: &nbsp;A Deep Learning Framework for Traffic Forecasting. &nbsp;10.24963/ijcai.2018/505</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Bin Zhao, Haopeng Li, Xiaoqiang Lu, Xuelong Li. &nbsp;Reconstructive Sequence-Graph Network for Video Summarization.10.1109/TPAMI.2021.3072117.</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Rucha Bhalchandra Joshi, Subhankar Mishra. &nbsp;Learning Graph Representations.</span></li></ul><p class="c1 c2"><span class="c0"></span></p></body></html>