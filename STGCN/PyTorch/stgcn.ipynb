{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eeda807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TimeBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network block that applies a temporal convolution to each node of\n",
    "    a graph in isolation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        \"\"\"\n",
    "        :param in_channels: Number of input features at each node in each time\n",
    "        step.\n",
    "        :param out_channels: Desired number of output channels at each node in\n",
    "        each time step.\n",
    "        :param kernel_size: Size of the 1D temporal kernel.\n",
    "        \"\"\"\n",
    "        super(TimeBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_nodes, num_timesteps,\n",
    "        num_features=in_channels)\n",
    "        :return: Output data of shape (batch_size, num_nodes,\n",
    "        num_timesteps_out, num_features_out=out_channels)\n",
    "        \"\"\"\n",
    "        # Convert into NCHW format for pytorch to perform convolutions.\n",
    "        X = X.permute(0, 3, 1, 2)\n",
    "        temp = self.conv1(X) + torch.sigmoid(self.conv2(X))\n",
    "        out = F.relu(temp + self.conv3(X))\n",
    "        # Convert back from NCHW to NHWC\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class STGCNBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network block that applies a temporal convolution on each node in\n",
    "    isolation, followed by a graph convolution, followed by another temporal\n",
    "    convolution on each node.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, spatial_channels, out_channels,\n",
    "                 num_nodes):\n",
    "        \"\"\"\n",
    "        :param in_channels: Number of input features at each node in each time\n",
    "        step.\n",
    "        :param spatial_channels: Number of output channels of the graph\n",
    "        convolutional, spatial sub-block.\n",
    "        :param out_channels: Desired number of output features at each node in\n",
    "        each time step.\n",
    "        :param num_nodes: Number of nodes in the graph.\n",
    "        \"\"\"\n",
    "        super(STGCNBlock, self).__init__()\n",
    "        self.temporal1 = TimeBlock(in_channels=in_channels,\n",
    "                                   out_channels=out_channels)\n",
    "        self.Theta1 = nn.Parameter(torch.FloatTensor(out_channels,\n",
    "                                                     spatial_channels))\n",
    "        self.temporal2 = TimeBlock(in_channels=spatial_channels,\n",
    "                                   out_channels=out_channels)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_nodes)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.Theta1.shape[1])\n",
    "        self.Theta1.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, X, A_hat):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_nodes, num_timesteps,\n",
    "        num_features=in_channels).\n",
    "        :param A_hat: Normalized adjacency matrix.\n",
    "        :return: Output data of shape (batch_size, num_nodes,\n",
    "        num_timesteps_out, num_features=out_channels).\n",
    "        \"\"\"\n",
    "        t = self.temporal1(X)\n",
    "        lfs = torch.einsum(\"ij,jklm->kilm\", [A_hat, t.permute(1, 0, 2, 3)])\n",
    "        # t2 = F.relu(torch.einsum(\"ijkl,lp->ijkp\", [lfs, self.Theta1]))\n",
    "        t2 = F.relu(torch.matmul(lfs, self.Theta1))\n",
    "        t3 = self.temporal2(t2)\n",
    "        return self.batch_norm(t3)\n",
    "        # return t3\n",
    "\n",
    "\n",
    "class STGCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatio-temporal graph convolutional network as described in\n",
    "    https://arxiv.org/abs/1709.04875v3 by Yu et al.\n",
    "    Input should have shape (batch_size, num_nodes, num_input_time_steps,\n",
    "    num_features).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_nodes, num_features, num_timesteps_input,\n",
    "                 num_timesteps_output):\n",
    "        \"\"\"\n",
    "        :param num_nodes: Number of nodes in the graph.\n",
    "        :param num_features: Number of features at each node in each time step.\n",
    "        :param num_timesteps_input: Number of past time steps fed into the\n",
    "        network.\n",
    "        :param num_timesteps_output: Desired number of future time steps\n",
    "        output by the network.\n",
    "        \"\"\"\n",
    "        super(STGCN, self).__init__()\n",
    "        self.block1 = STGCNBlock(in_channels=num_features, out_channels=64,\n",
    "                                 spatial_channels=16, num_nodes=num_nodes)\n",
    "        self.block2 = STGCNBlock(in_channels=64, out_channels=64,\n",
    "                                 spatial_channels=16, num_nodes=num_nodes)\n",
    "        self.last_temporal = TimeBlock(in_channels=64, out_channels=64)\n",
    "        self.fully = nn.Linear((num_timesteps_input - 2 * 5) * 64,\n",
    "                               num_timesteps_output)\n",
    "\n",
    "    def forward(self, A_hat, X):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_nodes, num_timesteps,\n",
    "        num_features=in_channels).\n",
    "        :param A_hat: Normalized adjacency matrix.\n",
    "        \"\"\"\n",
    "        out1 = self.block1(X, A_hat)\n",
    "        out2 = self.block2(out1, A_hat)\n",
    "        out3 = self.last_temporal(out2)\n",
    "        out4 = self.fully(out3.reshape((out3.shape[0], out3.shape[1], -1)))\n",
    "        return out4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
